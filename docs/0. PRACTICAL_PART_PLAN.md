# практическая часть дипломной работы

## последовательность выполнения практической части

### **Фаза 1: Минимальный рабочий прототип (2-3 )**

#### 1-2: Базовая кодовая база
```bash
/diplom-distributed-system/
├── cmd/
│   ├── api-gateway/     # Простой HTTP/gRPC прокси
│   ├── processor/       # Worker pool с базовой логикой
│   └── ingest/         # Приём данных
├── internal/
│   ├── models/         # Protobuf схемы
│   └── config/         # YAML конфигурация
├── docker/
│   └── docker-compose.yml
└── Makefile
```

**Действия:**
1. Создать базовые proto-файлы для сообщений
2. Реализовать простейший worker-pool (10-20 строк)
3. HTTP endpoint для приёма данных
4. In-memory очередь вместо Kafka/NATS
5. Простой docker-compose с 3 сервисами

#### 3: Первые тесты
- Unit-тесты для worker-pool
- Простой нагрузочный тест с `go test -bench`
- Базовые метрики через expvar

### **Фаза 2: Интеграция брокеров сообщений (2 )**

#### 4: NATS JetStream
```yaml
# docker-compose.yml дополнить:
nats:
  image: nats:2.10-alpine
  command: "-js -m 8222"
  ports:
    - "4222:4222"
    - "8222:8222"
```

- Подключить nats.go клиент
- Заменить in-memory очередь на JetStream
- Реализовать простой back-pressure

#### 5: Kafka
- Добавить Kafka в docker-compose (1 брокер)
- Реализовать dual-write (NATS + Kafka)


### **Фаза 3: Оптимизация и профилирование (2 )**

#### 6: Профилирование
```bash
# scripts/profile.sh
#!/bin/bash
go test -bench=. -cpuprofile=cpu.prof ./...
go tool pprof -http=:8080 cpu.prof
```

- Запустить pprof на локальной машине
- Сгенерировать flame graphs
- Выявить узкие места
- Оптимизировать hot paths

#### 7: Сетевые оптимизации
- Реализовать gRPC endpoint
- Добавить HTTP/2 server push (если применимо)
- Настроить connection pooling
- Измерить latency с помощью httptrace

### **Фаза 4: Нагрузочное тестирование (2 )**

#### 8: Подготовка тестового окружения
```yaml
# k6/scenarios/smoke.js
export let options = {
  stages: [
    { duration: '30s', target: 100 },
    { duration: '1m', target: 500 },
    { duration: '30s', target: 0 },
  ],
};
```

- Установить k6 локально
- Написать базовые сценарии (smoke, load, spike)
- Настроить Prometheus + Grafana в docker

#### 9: Проведение тестов
**Реалистичные цели для домашнего ПК:**
- 5,000-10,000 TPS (вместо 50,000)
- P95 < 100ms (вместо 50ms)
- 4 процессора вместо кластера

**Тесты:**
1. Baseline test (1 инстанс каждого сервиса)
2. Scaled test (docker-compose scale processor=4)
3. Stress test (до отказа)
4. Soak test (2 часа вместо 6)

### **Фаза 5: Документирование результатов (1 )**

#### 10: Сбор артефактов
```
/results/
├── benchmarks/
│   ├── baseline.txt
│   ├── optimized.txt
│   └── comparison.md
├── profiles/
│   ├── cpu.svg
│   ├── mem.svg
│   └── trace.json
├── metrics/
│   ├── grafana-dashboard.json
│   ├── prometheus-snapshots/
│   └── screenshots/
└── logs/
    └── k6-reports/
```

### **Фаза 6: Создание демонстрационных материалов (1 )**

1. **README.md** с quick start
2. **Makefile** с командами:
   ```makefile
   demo: docker-compose up -d
   test: k6 run scenarios/demo.js
   monitor: open http://localhost:3000
   ```
3. **Видео-демо** (5 мин) или GIF-анимации
4. **Jupyter notebook** с анализом результатов

### **Упрощения для домашних условий:**

1. **Вместо Kubernetes** → docker-compose с --scale
2. **Вместо 5 нод** → 1 машина с docker
3. **Вместо 50k TPS** → 5-10k TPS (всё равно впечатляет)
4. **Вместо distributed tracing** → простые логи с correlation ID
5. **Вместо внешнего хранилища** → SQLite/BadgerDB

### **Критические точки успеха:**

1. ** 3**: Должен работать базовый pipeline
2. ** 5**: Интеграция с message broker
3. ** 7**: Видимые улучшения от оптимизаций
4. ** 9**: Графики из Grafana для диплома

### **План Б (если времени мало):**

- Оставить только NATS (убрать Kafka)
- Упростить до 2 сервисов (ingest + processor)
- Сфокусироваться на worker-pool оптимизациях
- Использовать готовые docker images где возможно

**TL;DR**: Начать с простейшего работающего прототипа на Go, постепенно добавлять компоненты (NATS, профилирование, тесты), проводить реалистичные тесты на домашнем ПК с упором на относительные улучшения производительности, а не абсолютные цифры. Ключ к успеху - работающий код с воспроизводимыми тестами и красивыми графиками из Grafana.